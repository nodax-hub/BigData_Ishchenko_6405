{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "82OvPKEiEqjc"
   },
   "source": "# Введение в my_map_reduce модель на Python\n"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JQ2cvXLjICmI",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.078391Z",
     "start_time": "2025-05-13T13:42:03.071166Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "from typing import NamedTuple"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rv-XIjhTJPx3",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.098828Z",
     "start_time": "2025-05-13T13:42:03.095403Z"
    }
   },
   "source": [
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    age: int\n",
    "    social_contacts: int\n",
    "    gender: str"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.372266Z",
     "start_time": "2025-05-13T13:42:03.366771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def my_map(_, row: User):\n",
    "    if row.gender == 'female':\n",
    "        yield row.age, row\n",
    "\n",
    "\n",
    "def my_reduce(age: str, rows: Iterator[NamedTuple]):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in rows:\n",
    "        sum += row.social_contacts\n",
    "        count += 1\n",
    "    if count > 0:\n",
    "        yield age, sum / count\n",
    "    else:\n",
    "        yield age, 0"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "id": "vBKMgpG_ilaZ"
   },
   "cell_type": "markdown",
   "source": "Модель элемента данных"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5KV0Ze2vQgu5",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.393909Z",
     "start_time": "2025-05-13T13:42:03.389274Z"
    }
   },
   "source": [
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YFeqzyZxZIFZ"
   },
   "source": "Функция record_reader моделирует чтение элементов с диска или по сети."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "S5HR4E_GQoMJ",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.426503Z",
     "start_time": "2025-05-13T13:42:03.422332Z"
    }
   },
   "source": [
    "def record_reader():\n",
    "    return [(u.id, u) for u in input_collection]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "NeEoWla-ROUy",
    "outputId": "94ca6e0e-4644-4282-acbf-1759d7ba2918",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.451149Z",
     "start_time": "2025-05-13T13:42:03.443696Z"
    }
   },
   "source": "list(record_reader())",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, User(id=0, age=55, social_contacts=20, gender='male')),\n",
       " (1, User(id=1, age=25, social_contacts=240, gender='female')),\n",
       " (2, User(id=2, age=25, social_contacts=500, gender='female')),\n",
       " (3, User(id=3, age=33, social_contacts=800, gender='female'))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YB8orgPSZs8M",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.492255Z",
     "start_time": "2025-05-13T13:42:03.488675Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "74oyvDLaRmd5",
    "outputId": "c6147702-7153-47c7-a574-d5fe6abe29a8",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.541354Z",
     "start_time": "2025-05-13T13:42:03.535974Z"
    }
   },
   "source": [
    "map_output = flatten(map(lambda x: my_map(*x), record_reader()))\n",
    "map_output = list(map_output)  # materialize\n",
    "map_output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, User(id=1, age=25, social_contacts=240, gender='female')),\n",
       " (25, User(id=2, age=25, social_contacts=500, gender='female')),\n",
       " (33, User(id=3, age=33, social_contacts=800, gender='female'))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8ncYDJ3-VzDn",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.625133Z",
     "start_time": "2025-05-13T13:42:03.620576Z"
    }
   },
   "source": [
    "def group_by_key(iterable):\n",
    "    t = {}\n",
    "    for (k2, v2) in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "cKzY_6COWOA2",
    "outputId": "e6791b12-e409-47e9-bcd4-e9f8ca8611bd",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.691983Z",
     "start_time": "2025-05-13T13:42:03.687086Z"
    }
   },
   "source": [
    "shuffle_output = group_by_key(map_output)\n",
    "shuffle_output = list(shuffle_output)\n",
    "shuffle_output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25,\n",
       "  [User(id=1, age=25, social_contacts=240, gender='female'),\n",
       "   User(id=2, age=25, social_contacts=500, gender='female')]),\n",
       " (33, [User(id=3, age=33, social_contacts=800, gender='female')])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NlA7lkDDYL0t",
    "outputId": "6b25d03f-5c92-4f3b-f500-6d70acd598b7",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.749298Z",
     "start_time": "2025-05-13T13:42:03.743916Z"
    }
   },
   "source": [
    "reduce_output = flatten(map(lambda x: my_reduce(*x), shuffle_output))\n",
    "reduce_output = list(reduce_output)\n",
    "reduce_output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 370.0), (33, 800.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xf6qhHEtd6bI"
   },
   "source": [
    "Все действия одним конвейером!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dZaQGYxCdpw5",
    "outputId": "3f5c6425-e5c5-49d2-b2cd-ce58a9acc33c",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.792569Z",
     "start_time": "2025-05-13T13:42:03.787405Z"
    }
   },
   "source": "list(flatten(map(lambda x: my_reduce(*x), group_by_key(flatten(map(lambda x: my_map(*x), record_reader()))))))",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 370.0), (33, 800.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vq3EWRIpwSiJ"
   },
   "source": [
    "# **my_map_reduce**\n",
    "Выделим общую для всех пользователей часть системы в отдельную функцию высшего порядка. Это наиболее простая модель my_map_reduce, без учёта распределённого хранения данных.\n",
    "\n",
    "Пользователь для решения своей задачи реализует record_reader, my_map, my_reduce."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V1PZeQMwwVjc",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.833618Z",
     "start_time": "2025-05-13T13:42:03.828409Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def group_by_key(iterable):\n",
    "    t = {}\n",
    "    for (k2, v2) in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def my_map_reduce(record_reader, my_map, my_reduce):\n",
    "    return flatten(map(lambda x: my_reduce(*x), group_by_key(flatten(map(lambda x: my_map(*x), record_reader())))))"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFIVrimep678"
   },
   "source": [
    "## Спецификация my_map_reduce\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "f (k1, v1) -> (k2,v2)*\n",
    "g (k2, v2*) -> (k3,v3)*\n",
    "\n",
    "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "groupby ((k2,v2)*) -> (k2,v2*)*\n",
    "flatten (e2**) -> e2*\n",
    "\n",
    "mapreduce .map(f).flatten.groupby(k2).map(g).flatten\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtTFyqke3KGe"
   },
   "source": [
    "# Примеры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNhh5763w5Vn"
   },
   "source": "## SQL"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "QkyurnvGxBGk",
    "outputId": "84761282-d2ba-435a-e8d7-a85150730e10",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:03.893989Z",
     "start_time": "2025-05-13T13:42:03.884997Z"
    }
   },
   "source": [
    "from typing import NamedTuple  # requires python 3.6+\n",
    "from typing import Iterator\n",
    "\n",
    "\n",
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    age: int\n",
    "    social_contacts: int\n",
    "    gender: str\n",
    "\n",
    "\n",
    "input_collection = [\n",
    "    User(id=0, age=55, gender='male', social_contacts=20),\n",
    "    User(id=1, age=25, gender='female', social_contacts=240),\n",
    "    User(id=2, age=25, gender='female', social_contacts=500),\n",
    "    User(id=3, age=33, gender='female', social_contacts=800)\n",
    "]\n",
    "\n",
    "\n",
    "def my_map(_, row: User):\n",
    "    if row.gender == 'female':\n",
    "        yield row.age, row\n",
    "\n",
    "\n",
    "def my_reduce(age: str, rows: Iterator[NamedTuple]):\n",
    "    sum = 0\n",
    "    count = 0\n",
    "    for row in rows:\n",
    "        sum += row.social_contacts\n",
    "        count += 1\n",
    "    if count > 0:\n",
    "        yield age, sum / count\n",
    "    else:\n",
    "        yield age, 0\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    return [(u.id, u) for u in input_collection]\n",
    "\n",
    "\n",
    "output = my_map_reduce(record_reader, my_map, my_reduce)\n",
    "output = list(output)\n",
    "output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 370.0), (33, 800.0)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kNKYIeerx0nY"
   },
   "source": "## Matrix-Vector multiplication"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "rwcntRcCyi1V",
    "outputId": "606737ab-6b55-455c-931f-4fc45155f8a9",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.031813Z",
     "start_time": "2025-05-13T13:42:03.917800Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "import numpy as np\n",
    "\n",
    "mat = np.ones((5, 4))\n",
    "vec = np.random.rand(4)  # in-memory vector in all map tasks\n",
    "\n",
    "\n",
    "def my_map(coordinates: (int, int), value: int):\n",
    "    i, j = coordinates\n",
    "    yield i, value * vec[j]\n",
    "\n",
    "\n",
    "def my_reduce(i: int, products: Iterator[NamedTuple]):\n",
    "    sum = 0\n",
    "    for p in products:\n",
    "        sum += p\n",
    "    yield i, sum\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for i in range(mat.shape[0]):\n",
    "        for j in range(mat.shape[1]):\n",
    "            yield (i, j), mat[i, j]\n",
    "\n",
    "\n",
    "output = my_map_reduce(record_reader, my_map, my_reduce)\n",
    "output = list(output)\n",
    "output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, np.float64(1.742220737469483)),\n",
       " (1, np.float64(1.742220737469483)),\n",
       " (2, np.float64(1.742220737469483)),\n",
       " (3, np.float64(1.742220737469483)),\n",
       " (4, np.float64(1.742220737469483))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruZREYdi2o4O"
   },
   "source": "## Inverted index"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "vt9H9Alf3TYv",
    "outputId": "51aeffc9-e111-4607-bd84-cfcc7b56f238",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.053339Z",
     "start_time": "2025-05-13T13:42:04.046087Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"it is what it is\"\n",
    "d2 = \"what is it\"\n",
    "d3 = \"it is a banana\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for (docid, document) in enumerate(documents):\n",
    "        yield \"{}\".format(docid), document\n",
    "\n",
    "\n",
    "def my_map(doc_id: str, body: str):\n",
    "    for word in set(body.split(' ')):\n",
    "        yield word, doc_id\n",
    "\n",
    "\n",
    "def my_reduce(word: str, doc_ids: Iterator[str]):\n",
    "    yield word, sorted(doc_ids)\n",
    "\n",
    "\n",
    "output = my_map_reduce(record_reader, my_map, my_reduce)\n",
    "output = list(output)\n",
    "output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('it', ['0', '1', '2']),\n",
       " ('is', ['0', '1', '2']),\n",
       " ('what', ['0', '1']),\n",
       " ('banana', ['2']),\n",
       " ('a', ['2'])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R7az-6DA6qr2"
   },
   "source": [
    "## WordCount"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dN-nbtgG6uYG",
    "outputId": "24117576-7931-401d-a581-28e246b23453",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.099790Z",
     "start_time": "2025-05-13T13:42:04.091846Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3]\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for (docid, document) in enumerate(documents):\n",
    "        for (lineid, line) in enumerate(document.split('\\n')):\n",
    "            yield \"{}:{}\".format(docid, lineid), line\n",
    "\n",
    "\n",
    "def my_map(docId: str, line: str):\n",
    "    for word in line.split(\" \"):\n",
    "        yield word, 1\n",
    "\n",
    "\n",
    "def my_reduce(word: str, counts: Iterator[int]):\n",
    "    sum = 0\n",
    "    for c in counts:\n",
    "        sum += c\n",
    "    yield word, sum\n",
    "\n",
    "\n",
    "output = my_map_reduce(record_reader, my_map, my_reduce)\n",
    "output = list(output)\n",
    "output"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 3), ('it', 9), ('is', 9), ('what', 5), ('a', 1), ('banana', 1)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-jRAcYCAkkk"
   },
   "source": [
    "# my_map_reduce Distributed\n",
    "\n",
    "Добавляется в модель фабрика RECORDREARER-ов --- input_format, функция распределения промежуточных результатов по партициям partitioner, и функция COMBINER для частичной аггрегации промежуточных результатов до распределения по новым партициям."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nw-b-xJsApgW",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.144363Z",
     "start_time": "2025-05-13T13:42:04.135869Z"
    }
   },
   "source": [
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def group_by_key(iterable):\n",
    "    t = {}\n",
    "    for (k2, v2) in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def groupbykey_distributed(map_partitions, partitioner):\n",
    "    global reducers\n",
    "    partitions = [dict() for _ in range(reducers)]\n",
    "    for map_partition in map_partitions:\n",
    "        for (k2, v2) in map_partition:\n",
    "            p = partitions[partitioner(k2)]\n",
    "            p[k2] = p.get(k2, []) + [v2]\n",
    "    return [(partition_id, sorted(partition.items(), key=lambda x: x[0])) for (partition_id, partition) in\n",
    "            enumerate(partitions)]\n",
    "\n",
    "\n",
    "def partitioner(obj):\n",
    "    global reducers\n",
    "    return hash(obj) % reducers\n",
    "\n",
    "\n",
    "def map_reduce_distributed(input_format, my_map, my_reduce, partitioner=partitioner, combiner=None):\n",
    "    map_partitions = map(lambda record_reader: flatten(map(lambda k1v1: my_map(*k1v1), record_reader)), input_format())\n",
    "\n",
    "    if combiner is not None:\n",
    "        map_partitions = map(lambda map_partition:\n",
    "                             flatten(map(lambda k2v2: combiner(*k2v2), group_by_key(map_partition))), map_partitions)\n",
    "\n",
    "    reduce_partitions = groupbykey_distributed(map_partitions, partitioner)  # shuffle\n",
    "    reduce_outputs = map(lambda reduce_partition:\n",
    "                         (reduce_partition[0],\n",
    "                          flatten(map(lambda reduce_input_group:\n",
    "                                      my_reduce(*reduce_input_group), reduce_partition[1]))), reduce_partitions)\n",
    "\n",
    "    print(\"{} key-value pairs were sent over a network.\".format(\n",
    "        sum([len(vs) for (k, vs) in\n",
    "             flatten([partition for (partition_id, partition) in reduce_partitions])])))\n",
    "\n",
    "    return reduce_outputs"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxirlf3XqZxY"
   },
   "source": [
    "## Спецификация my_map_reduce Distributed\n",
    "\n",
    "\n",
    "```\n",
    "f (k1, v1) -> (k2,v2)*\n",
    "g (k2, v2*) -> (k3,v3)*\n",
    "\n",
    "e1 (k1, v1)\n",
    "e2 (k2, v2)\n",
    "partition1 (k2, v2)*\n",
    "partition2 (k2, v2*)*\n",
    "\n",
    "flatmap (e1->e2*, e1*) -> partition1*\n",
    "groupby (partition1*) -> partition2*\n",
    "\n",
    "mapreduce ((k1,v1)*) -> (k3,v3)*\n",
    "mapreduce .flatmap(f).groupby(k2).flatmap(g)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWYw_CpbbY3C"
   },
   "source": "## WordCount"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "uR_zfGFkMZlp",
    "outputId": "c8d46167-473d-43b9-881a-2396991b3731",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.213218Z",
     "start_time": "2025-05-13T13:42:04.203836Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "\n",
    "d1 = \"\"\"\n",
    "it is what it is\n",
    "it is what it is\n",
    "it is what it is\"\"\"\n",
    "d2 = \"\"\"\n",
    "what is it\n",
    "what is it\"\"\"\n",
    "d3 = \"\"\"\n",
    "it is a banana\"\"\"\n",
    "documents = [d1, d2, d3, d1, d2, d3]\n",
    "\n",
    "maps = 3\n",
    "reducers = 2\n",
    "\n",
    "\n",
    "def input_format():\n",
    "    global maps\n",
    "\n",
    "    def record_reader(split):\n",
    "        for (docid, document) in enumerate(split):\n",
    "            for (lineid, line) in enumerate(document.split('\\n')):\n",
    "                yield \"{}:{}\".format(docid, lineid), line\n",
    "\n",
    "    split_size = int(np.ceil(len(documents) / maps))\n",
    "    for i in range(0, len(documents), split_size):\n",
    "        yield record_reader(documents[i:i + split_size])\n",
    "\n",
    "\n",
    "def my_map(docId: str, line: str):\n",
    "    for word in line.split(\" \"):\n",
    "        yield word, 1\n",
    "\n",
    "\n",
    "def my_reduce(word: str, counts: Iterator[int]):\n",
    "    sum = 0\n",
    "    for c in counts:\n",
    "        sum += c\n",
    "    yield word, sum\n",
    "\n",
    "\n",
    "# try to set COMBINER=REDUCER and look at the number of values sent over the network\n",
    "partitioned_output = map_reduce_distributed(input_format, my_map, my_reduce, combiner=None)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, [('', 6), ('banana', 2), ('is', 18), ('it', 18)]),\n",
       " (1, [('a', 2), ('what', 10)])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCJGx8IQ87xS"
   },
   "source": [
    "## TeraSort"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "P2v8v1v_8_YR",
    "outputId": "e0987c25-9757-46cb-8e55-d5d2adfbee2b",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.303683Z",
     "start_time": "2025-05-13T13:42:04.293219Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "input_values = np.random.rand(30)\n",
    "maps = 3\n",
    "reducers = 2\n",
    "min_value = 0.0\n",
    "max_value = 1.0\n",
    "\n",
    "\n",
    "def input_format():\n",
    "    global maps\n",
    "\n",
    "    def record_reader(split):\n",
    "        for value in split:\n",
    "            yield value, None\n",
    "\n",
    "    split_size = int(np.ceil(len(input_values) / maps))\n",
    "    for i in range(0, len(input_values), split_size):\n",
    "        yield record_reader(input_values[i:i + split_size])\n",
    "\n",
    "\n",
    "def my_map(value: int, _):\n",
    "    yield value, None\n",
    "\n",
    "\n",
    "def partitioner(key):\n",
    "    global reducers\n",
    "    global max_value\n",
    "    global min_value\n",
    "    bucket_size = (max_value - min_value) / reducers\n",
    "    bucket_id = 0\n",
    "    while (key > (bucket_id + 1) * bucket_size) and ((bucket_id + 1) * bucket_size < max_value):\n",
    "        bucket_id += 1\n",
    "    return bucket_id\n",
    "\n",
    "\n",
    "def my_reduce(value: int, _):\n",
    "    yield None, value\n",
    "\n",
    "\n",
    "partitioned_output = map_reduce_distributed(input_format, my_map, my_reduce, combiner=None, partitioner=partitioner)\n",
    "partitioned_output = [(partition_id, list(partition)) for (partition_id, partition) in partitioned_output]\n",
    "partitioned_output"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 key-value pairs were sent over a network.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [(None, np.float64(0.022566506217998494)),\n",
       "   (None, np.float64(0.11183061640214509)),\n",
       "   (None, np.float64(0.11922751479960814)),\n",
       "   (None, np.float64(0.13744666757200008)),\n",
       "   (None, np.float64(0.13841118544520625)),\n",
       "   (None, np.float64(0.1388860785768995)),\n",
       "   (None, np.float64(0.15741275626144602)),\n",
       "   (None, np.float64(0.15988108632682096)),\n",
       "   (None, np.float64(0.1805433015933614)),\n",
       "   (None, np.float64(0.18080343507309404)),\n",
       "   (None, np.float64(0.2499028063670572)),\n",
       "   (None, np.float64(0.2938295823738537)),\n",
       "   (None, np.float64(0.29708762514938825)),\n",
       "   (None, np.float64(0.30011224970796446)),\n",
       "   (None, np.float64(0.30533032755860545)),\n",
       "   (None, np.float64(0.35031309540844435)),\n",
       "   (None, np.float64(0.3614859964416267)),\n",
       "   (None, np.float64(0.3628712403828649)),\n",
       "   (None, np.float64(0.42900034790454855))]),\n",
       " (1,\n",
       "  [(None, np.float64(0.5370053080266557)),\n",
       "   (None, np.float64(0.5564309682878759)),\n",
       "   (None, np.float64(0.7218870047875557)),\n",
       "   (None, np.float64(0.7343313967217969)),\n",
       "   (None, np.float64(0.736302891049887)),\n",
       "   (None, np.float64(0.744228013533191)),\n",
       "   (None, np.float64(0.8048325212860773)),\n",
       "   (None, np.float64(0.8588759207099401)),\n",
       "   (None, np.float64(0.8816150348713068)),\n",
       "   (None, np.float64(0.9358463712635383)),\n",
       "   (None, np.float64(0.9453592276374494))])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MQhoJaVZI93G",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.398596Z",
     "start_time": "2025-05-13T13:42:04.395648Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iy65YJTH99iT"
   },
   "source": [
    "# Упражнения\n",
    "Упражнения взяты из Rajaraman A., Ullman J. D. Mining of massive datasets. – Cambridge University Press, 2011.\n",
    "\n",
    "\n",
    "Для выполнения заданий переопределите функции record_reader, my_map, my_reduce. Для модели распределённой системы может потребоваться переопределение функций PARTITION и COMBINER."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfvAeZm3S8S8"
   },
   "source": [
    "### Максимальное значение ряда\n",
    "\n",
    "Разработайте my_map_reduce алгоритм, который находит максимальное число входного списка чисел."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3GRA1JR-Tkbg",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.471375Z",
     "start_time": "2025-05-13T13:42:04.465125Z"
    }
   },
   "source": [
    "from typing import Iterator\n",
    "\n",
    "# ─ входной «поток» значений\n",
    "input = [42, -7, 19, 23, 58, 99, 12, 0, -3, 77]\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    \"\"\"\n",
    "    Последовательно отдаём элементы в формате (ключ, значение).\n",
    "    Ключом здесь служит строковый индекс, а значением — само число.\n",
    "    \"\"\"\n",
    "    for idx, num in enumerate(input):\n",
    "        yield str(idx), num\n",
    "\n",
    "\n",
    "def my_map(num_id: str, num: int):\n",
    "    \"\"\"\n",
    "    Отдаём все записи в один и тот же раздел (ключ 0),\n",
    "    чтобы редьюсер видел вообще все числа.\n",
    "    \"\"\"\n",
    "    yield 0, num\n",
    "\n",
    "\n",
    "def my_reduce(dummy_key: str, nums: Iterator[int]):\n",
    "    \"\"\"\n",
    "    Получаем все числа и выводим их максимум.\n",
    "    dummy_key всегда '0', потому что my_map отдаёт ровно один ключ.\n",
    "    \"\"\"\n",
    "    yield dummy_key, max(nums)\n",
    "\n",
    "\n",
    "# Проверяем работу алгоритма\n",
    "print(\"MAX:\", list(my_map_reduce(record_reader, my_map, my_reduce)))  # [('0', 99)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAX: [(0, 99)]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k86bXnqZTk-U"
   },
   "source": [
    "### Арифметическое среднее\n",
    "\n",
    "Разработайте my_map_reduce алгоритм, который находит арифметическое среднее.\n",
    "\n",
    "$$\\overline{X} = \\frac{1}{n}\\sum_{i=0}^{n} x_i$$\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MPoY5pkfUNZf",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.572540Z",
     "start_time": "2025-05-13T13:42:04.567187Z"
    }
   },
   "source": [
    "input = [3, 3, 3, 3, 8, 8, 8, 8]  # новые данные для примера\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for idx, num in enumerate(input):\n",
    "        yield str(idx), num\n",
    "\n",
    "\n",
    "def my_map(num_id: str, num: int):\n",
    "    \"\"\"Аналогично предыдущему примеру: отправляем всё в один редьюсер.\"\"\"\n",
    "    yield 0, num\n",
    "\n",
    "\n",
    "def my_reduce(dummy_key: str, nums: Iterator[int]):\n",
    "    nums = list(nums)  # материализуем, чтобы посчитать len\n",
    "    yield dummy_key, sum(nums) / len(nums)\n",
    "\n",
    "\n",
    "print(\"AVERAGE:\", list(my_map_reduce(record_reader, my_map, my_reduce)))  # [('0', 5.5)]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVERAGE: [(0, 5.5)]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xanzszhsIlLe"
   },
   "source": [
    "### GroupByKey на основе сортировки\n",
    "\n",
    "Реализуйте groupByKey на основе сортировки, проверьте его работу на примерах"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hQPn3USsIkEC",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.681328Z",
     "start_time": "2025-05-13T13:42:04.674278Z"
    }
   },
   "source": [
    "def groupbykey_sorted(pairs):\n",
    "    \"\"\"\n",
    "    Принимает неупорядоченную последовательность кортежей (key, value),\n",
    "    сортирует по key и вручную «собирает» списки значений для каждого key.\n",
    "    Возвращает генератор (key, [value, value, …]).\n",
    "    \"\"\"\n",
    "    pairs_sorted = sorted(pairs, key=lambda kv: kv[0])  # обязательная сортировка\n",
    "    current_key = None  # ключ текущей «корзинки»\n",
    "    bucket = []  # список значений, относящихся к current_key\n",
    "    for key, val in pairs_sorted:\n",
    "        if key != current_key and bucket:\n",
    "            # Ключ сменился ⇒ старая корзинка закончена — отдаём наружу\n",
    "            yield current_key, bucket\n",
    "            bucket = []\n",
    "        bucket.append(val)\n",
    "        current_key = key\n",
    "\n",
    "    # доотдаём «хвост», если он есть\n",
    "    if bucket:\n",
    "        yield current_key, bucket\n",
    "\n",
    "\n",
    "# Несколько демонстрационных наборов\n",
    "e1 = [('a', 1), ('b', 2), ('a', 3), ('b', 4), ('c', 5)]\n",
    "e2 = [('x', 10), ('y', 20), ('x', 30), ('z', 40), ('y', 50)]\n",
    "e3 = [('apple', 'red'), ('banana', 'yellow'),\n",
    "      ('apple', 'green'), ('banana', 'green')]\n",
    "\n",
    "print(\"GROUPBY #1:\", list(groupbykey_sorted(e1)))\n",
    "print(\"GROUPBY #2:\", list(groupbykey_sorted(e2)))\n",
    "print(\"GROUPBY #3:\", list(groupbykey_sorted(e3)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUPBY #1: [('a', [1, 3]), ('b', [2, 4]), ('c', [5])]\n",
      "GROUPBY #2: [('x', [10, 30]), ('y', [20, 50]), ('z', [40])]\n",
      "GROUPBY #3: [('apple', ['red', 'green']), ('banana', ['yellow', 'green'])]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SgEjCZyGnu6"
   },
   "source": [
    "### Drop duplicates (set construction, unique elements, distinct)\n",
    "\n",
    "Реализуйте распределённую операцию исключения дубликатов"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "okjbyApjGhMt",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.733787Z",
     "start_time": "2025-05-13T13:42:04.726398Z"
    }
   },
   "source": [
    "input_values = [2, 2, 2, 4, 5, 5, 6, 7, 8]  # исходные данные\n",
    "maps, reducers = 3, 2  # параметризация кластера\n",
    "\n",
    "\n",
    "def record_reader(split):\n",
    "    \"\"\"\n",
    "    Читает «кусок» (split) входного массива и выдаёт (key, None),\n",
    "    где key = само значение. None — потому что полезных данных,\n",
    "    кроме ключа, нам не требуется.\n",
    "    \"\"\"\n",
    "    for v in split:\n",
    "        yield v, None\n",
    "\n",
    "\n",
    "def input_format():\n",
    "    \"\"\"\n",
    "    Делит input_values на `maps` примерно одинаковых частей\n",
    "    и отдаёт итератор из record_reader-ов.\n",
    "    \"\"\"\n",
    "    chunk = int(np.ceil(len(input_values) / maps))\n",
    "    for pos in range(0, len(input_values), chunk):\n",
    "        yield record_reader(input_values[pos:pos + chunk])\n",
    "\n",
    "\n",
    "def my_map(v, _):\n",
    "    yield v, None  # ключ = значение, полезная нагрузка не нужна\n",
    "\n",
    "\n",
    "def partitioner(key, reducers=reducers):\n",
    "    \"\"\"\n",
    "    Простейший хэш-разделитель: равномерно раскидываем ключи\n",
    "    по `reducers` редьюсерам.\n",
    "    \"\"\"\n",
    "    return hash(key) % reducers\n",
    "\n",
    "\n",
    "def my_reduce(key, _):\n",
    "    \"\"\"\n",
    "    До редьюсера доходит либо один экземпляр ключа,\n",
    "    либо несколько (если дубликаты попали в тот же раздел) —\n",
    "    в любом случае надо вывести ровно по одному key.\n",
    "    \"\"\"\n",
    "    yield key, None\n",
    "\n",
    "\n",
    "distinct_out = [(pid, list(data))\n",
    "                for pid, data in map_reduce_distributed(input_format, my_map, my_reduce,\n",
    "                                                        combiner=None,\n",
    "                                                        partitioner=partitioner)]\n",
    "print(\"DISTINCT partitions:\", distinct_out)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 key-value pairs were sent over a network.\n",
      "DISTINCT partitions: [(0, [(2, None), (4, None), (6, None), (8, None)]), (1, [(5, None), (7, None)])]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7sRGoTXuJze"
   },
   "source": [
    "# Операторы реляционной алгебры\n",
    "### Selection (Выборка)\n",
    "\n",
    "**The Map Function**: Для  каждого кортежа $t \\in R$ вычисляется истинность предиката $C$. В случае истины создаётся пара ключ-значение $(t, t)$. В паре ключ и значение одинаковы, равны $t$.\n",
    "\n",
    "**The Reduce Function:** Роль функции Reduce выполняет функция идентичности, которая возвращает то же значение, что получила на вход.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4nKIKe59uIfc",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.798337Z",
     "start_time": "2025-05-13T13:42:04.792940Z"
    }
   },
   "source": [
    "input = [13, 26, 37, 40, 42, 53, 60, 75, 88, 91]\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for idx, num in enumerate(input):\n",
    "        yield str(idx), num\n",
    "\n",
    "\n",
    "def my_map(idx, num):\n",
    "    \"\"\"\n",
    "    Если число чётное — пропускаем его дальше, иначе ничего не yield'им.\n",
    "    \"\"\"\n",
    "    if num % 2 == 0:\n",
    "        yield num, num\n",
    "\n",
    "\n",
    "def my_reduce(num, duplicates):\n",
    "    \"\"\"\n",
    "    Собираем дубликаты (они возможны, если вход содержал одно и то же число\n",
    "    несколько раз) и оставляем список, чтобы увидеть «сколько раз встретилось».\n",
    "    \"\"\"\n",
    "    yield num, list(duplicates)\n",
    "\n",
    "\n",
    "print(\"EVEN filter:\", list(my_map_reduce(record_reader, my_map, my_reduce)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVEN filter: [(26, [26]), (40, [40]), (42, [42]), (60, [60]), (88, [88])]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w27Ca-_Ku85V"
   },
   "source": [
    "### Projection (Проекция)\n",
    "\n",
    "Проекция на множество атрибутов $S$.\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $t \\in R$ создайте кортеж $t′$, исключая  из $t$ те значения, атрибуты которых не принадлежат  $S$. Верните пару $(t′, t′)$.\n",
    "\n",
    "**The Reduce Function:** Для каждого ключа $t′$, созданного любой Map задачей, вы получаете одну или несколько пар $(t′, t′)$. Reduce функция преобразует $(t′, [t′, t′, . . . , t′])$ в $(t′, t′)$, так, что для ключа $t′$ возвращается одна пара  $(t′, t′)$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BEvuY4GqvhS6",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.850422Z",
     "start_time": "2025-05-13T13:42:04.843347Z"
    }
   },
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "class User(NamedTuple):\n",
    "    id: int\n",
    "    age: int\n",
    "    social_contacts: int\n",
    "    gender: str\n",
    "\n",
    "\n",
    "users = [\n",
    "    User(0, 44, 15, 'male'),\n",
    "    User(1, 29, 300, 'female'),\n",
    "    User(2, 31, 410, 'female'),\n",
    "    User(3, 38, 910, 'female')\n",
    "]\n",
    "attributes = ['age', 'gender']  # поля, которые нужно оставить\n",
    "\n",
    "\n",
    "def my_map(_, row: User):\n",
    "    \"\"\"\n",
    "    Достаём нужные атрибуты (age, gender) и используем их и как ключ,\n",
    "    и как значение (чтобы редьюсер увидел их «сырьём»).\n",
    "    \"\"\"\n",
    "    proj = tuple(getattr(row, attr) for attr in attributes)\n",
    "    yield proj, proj\n",
    "\n",
    "\n",
    "def my_reduce(proj, _):\n",
    "    \"\"\"Никакой агрегации не нужно — просто повторяем ключ/значение.\"\"\"\n",
    "    yield proj, proj\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    return [(u.id, u) for u in users]\n",
    "\n",
    "\n",
    "print(\"PROJECTION:\", list(my_map_reduce(record_reader, my_map, my_reduce)))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECTION: [((44, 'male'), (44, 'male')), ((29, 'female'), (29, 'female')), ((31, 'female'), (31, 'female')), ((38, 'female'), (38, 'female'))]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gau6lKXvn2R"
   },
   "source": [
    "### Union (Объединение)\n",
    "\n",
    "**The Map Function:** Превратите каждый входной кортеж $t$ в пару ключ-значение $(t, t)$.\n",
    "\n",
    "**The Reduce Function:** С каждым ключом $t$ будет ассоциировано одно или два значений. В обоих случаях создайте $(t, t)$ в качестве выходного значения."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Sns7a5agv3nw",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.923622Z",
     "start_time": "2025-05-13T13:42:04.917964Z"
    }
   },
   "source": [
    "R = users  # «левая» коллекция\n",
    "S = [\n",
    "    User(0, 44, 1_500_000, 'male'),  # отличаются только social_contacts\n",
    "    User(1, 29, 300, 'female'),\n",
    "    User(2, 31, 410, 'female'),\n",
    "    User(3, 38, 910, 'female')\n",
    "]\n",
    "\n",
    "\n",
    "def my_map(_, row):\n",
    "    # ключом делаем сам объект User: одинаковые записи попадут в один редьюсер\n",
    "    yield row, row\n",
    "\n",
    "\n",
    "def my_reduce(row_key, _):\n",
    "    \"\"\"\n",
    "    row_key — это уже уникальный объект User, дошедший до редьюсера.\n",
    "    values нам не нужны: если таких объектов было несколько (дубликаты из R и S),\n",
    "    my_map_reduce сгруппировал их по этому ключу.\n",
    "    \"\"\"\n",
    "    yield row_key, None\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    return [(u.id, u) for u in R] + [(u.id, u) for u in S]\n",
    "\n",
    "\n",
    "union_res = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "print(\"UNION size:\", len(union_res))\n",
    "print(\"UNION full:\", union_res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNION size: 5\n",
      "UNION full: [(User(id=0, age=44, social_contacts=15, gender='male'), None), (User(id=1, age=29, social_contacts=300, gender='female'), None), (User(id=2, age=31, social_contacts=410, gender='female'), None), (User(id=3, age=38, social_contacts=910, gender='female'), None), (User(id=0, age=44, social_contacts=1500000, gender='male'), None)]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQ8TuEbjv4J8"
   },
   "source": [
    "### Intersection (Пересечение)\n",
    "\n",
    "**The Map Function:** Превратите каждый кортеж $t$ в пары ключ-значение $(t, t)$.\n",
    "\n",
    "**The Reduce Function:** Если для ключа $t$ есть список из двух элементов $[t, t]$ $-$ создайте пару $(t, t)$. Иначе, ничего не создавайте."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XKlBZh4IwERR",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:04.964017Z",
     "start_time": "2025-05-13T13:42:04.958918Z"
    }
   },
   "source": [
    "def my_map(_, row):\n",
    "    yield row, row\n",
    "\n",
    "\n",
    "def my_reduce(_, rows):\n",
    "    rows = list(rows)\n",
    "    if len(rows) == 2:  # встретился в обеих коллекциях\n",
    "        yield rows[0], None\n",
    "\n",
    "\n",
    "inter_res = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "print(\"INTERSECT:\", inter_res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INTERSECT: [(User(id=1, age=29, social_contacts=300, gender='female'), None), (User(id=2, age=31, social_contacts=410, gender='female'), None), (User(id=3, age=38, social_contacts=910, gender='female'), None)]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVOpqoY3wE5k"
   },
   "source": [
    "### Difference (Разница)\n",
    "\n",
    "**The Map Function:** Для кортежа $t \\in R$, создайте пару $(t, R)$, и для кортежа $t \\in S$, создайте пару $(t, S)$. Задумка заключается в том, чтобы значение пары было именем отношения $R$ or $S$, которому принадлежит кортеж (а лучше, единичный бит, по которому можно два отношения различить $R$ or $S$), а не весь набор атрибутов отношения.\n",
    "\n",
    "**The Reduce Function:** Для каждого ключа $t$, если соответствующее значение является списком $[R]$, создайте пару $(t, t)$. В иных случаях не предпринимайте действий."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QE_AC09lwZIZ",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.017673Z",
     "start_time": "2025-05-13T13:42:05.011542Z"
    }
   },
   "source": [
    "def my_map(_, row, tag):\n",
    "    \"\"\"\n",
    "    tag хранит маркер: 'R' если элемент пришёл из R, 'S' — из S.\n",
    "    \"\"\"\n",
    "    yield row, tag\n",
    "\n",
    "\n",
    "def my_reduce(row, tags):\n",
    "    \"\"\"\n",
    "    Элемент остаётся, если присутствовал хотя бы один раз в R\n",
    "    и ни разу в S.\n",
    "    \"\"\"\n",
    "    tags = list(tags)\n",
    "    if 'R' in tags and 'S' not in tags:\n",
    "        yield row, None\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    return [(u.id, u, 'R') for u in R] + [(u.id, u, 'S') for u in S]\n",
    "\n",
    "\n",
    "diff_res = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "print(\"R \\\\ S:\", diff_res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R \\ S: [(User(id=0, age=44, social_contacts=15, gender='male'), None)]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8I58V2VwhSm"
   },
   "source": [
    "### Natural Join\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $(a, b)$ отношения $R$, создайте пару $(b,(R, a))$. Для каждого кортежа $(b, c)$ отношения $S$, создайте пару $(b,(S, c))$.\n",
    "\n",
    "**The Reduce Function:** Каждый ключ $b$ будет асоциирован со списком пар, которые принимают форму либо $(R, a)$, либо $(S, c)$. Создайте все пары, одни, состоящие из  первого компонента $R$, а другие, из первого компонента $S$, то есть $(R, a)$ и $(S, c)$. На выходе вы получаете последовательность пар ключ-значение из списков ключей и значений. Ключ не нужен. Каждое значение, это тройка $(a, b, c)$ такая, что $(R, a)$ и $(S, c)$ это принадлежат входному списку значений."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yHiuuTctw86I",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.079152Z",
     "start_time": "2025-05-13T13:42:05.071641Z"
    }
   },
   "source": [
    "class Employee(NamedTuple):\n",
    "    id: int\n",
    "    salary: float\n",
    "\n",
    "\n",
    "employees = [\n",
    "    Employee(0, 350.0),\n",
    "    Employee(1, 450.0),\n",
    "    Employee(2, 2300.0),\n",
    "    Employee(3, 7000.0)\n",
    "]\n",
    "\n",
    "\n",
    "def my_map(_, row, src):\n",
    "    \"\"\"\n",
    "    src указывает источник ('U' — User, 'E' — Employee).\n",
    "    В значение кладём кортеж (тип, полезные данные).\n",
    "    \"\"\"\n",
    "    if src == 'U':\n",
    "        yield row.id, ('U', row.gender)\n",
    "    else:\n",
    "        yield row.id, ('E', row.salary)\n",
    "\n",
    "\n",
    "def my_reduce(id_, items):\n",
    "    \"\"\"\n",
    "    Собираем всё под одинаковым id и формируем декартово произведение\n",
    "    между User-полом и зарплатой Employee.\n",
    "    \"\"\"\n",
    "    genders = [v for typ, v in items if typ == 'U']  # 'male' / 'female'\n",
    "    salaries = [v for typ, v in items if typ == 'E']  # float\n",
    "    for g in genders:\n",
    "        for s in salaries:\n",
    "            yield id_, g, s\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    return ([(u.id, u, 'U') for u in users] +\n",
    "            [(e.id, e, 'E') for e in employees])\n",
    "\n",
    "\n",
    "join_res = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "print(\"THETA JOIN:\", join_res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THETA JOIN: [(0, 'male', 350.0), (1, 'female', 450.0), (2, 'female', 2300.0), (3, 'female', 7000.0)]\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kYdlr0YUxE27"
   },
   "source": [
    "### Grouping and Aggregation (Группировка и аггрегация)\n",
    "\n",
    "**The Map Function:** Для каждого кортежа $(a, b, c$) создайте пару $(a, b)$.\n",
    "\n",
    "**The Reduce Function:** Ключ представляет ту или иную группу. Примение аггрегирующую операцию $\\theta$ к списку значений $[b1, b2, . . . , bn]$ ассоциированных с ключом $a$. Возвращайте в выходной поток $(a, x)$, где $x$ результат применения  $\\theta$ к списку. Например, если $\\theta$ это $SUM$, тогда $x = b1 + b2 + · · · + bn$, а если $\\theta$ is $MAX$, тогда $x$ это максимальное из значений $b1, b2, . . . , bn$."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MLPckfEGxico",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.155156Z",
     "start_time": "2025-05-13T13:42:05.149583Z"
    }
   },
   "source": [
    "def my_map(_, row: User):\n",
    "    yield row.gender, row.social_contacts\n",
    "\n",
    "\n",
    "def my_reduce(gender, contacts, agg_op=sum):\n",
    "    \"\"\"\n",
    "    contacts — итератор всех social_contacts для данного пола.\n",
    "    Применяем выбранную агрегат-функцию\n",
    "    \"\"\"\n",
    "    yield gender, agg_op(contacts)\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    return [(u.id, u) for u in users]\n",
    "\n",
    "\n",
    "agg_res = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "print(\"AGGREGATE:\", agg_res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGGREGATE: [('male', 15), ('female', 1620)]\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03IffTEOJgOb"
   },
   "source": "#"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIrRgvG4RIS4"
   },
   "source": [
    "### Matrix-Vector multiplication\n",
    "\n",
    "Случай, когда вектор не помещается в памяти Map задачи\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KQhDbiL3zS9r",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.204585Z",
     "start_time": "2025-05-13T13:42:05.197292Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.random.randint(1, 5, size=(5, 4))  # случайная матрица 5×4\n",
    "v = np.random.rand(4)  # длина 4\n",
    "\n",
    "\n",
    "def my_map(coords, val):\n",
    "    \"\"\"\n",
    "    coords = (i, j)\n",
    "    Для каждой позиции (i,j) создаём пару (i, (j, val)),\n",
    "    где val -- либо A[i, j], либо v[j] (подмешивается в record_reader).\n",
    "    \"\"\"\n",
    "    i, j = coords\n",
    "    yield i, (j, val)\n",
    "\n",
    "\n",
    "def my_reduce(i, pairs):\n",
    "    \"\"\"\n",
    "    pairs содержит и элементы строки A[i,*], и все v[*].\n",
    "    Для корректности считаем произведение только там,\n",
    "    где «под нужным j» встретилось ровно два значения — A_ij и v_j.\n",
    "    \"\"\"\n",
    "    cache = {}\n",
    "    for j, x in pairs:\n",
    "        cache.setdefault(j, []).append(x)\n",
    "    dot = 0.0\n",
    "    for j, two_vals in cache.items():\n",
    "        if len(two_vals) == 2:\n",
    "            dot += two_vals[0] * two_vals[1]\n",
    "    yield i, float(dot)\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    \"\"\"\n",
    "    Пробегаем все координаты матрицы:\n",
    "      - публикуем A[i,j]\n",
    "      - сразу же публикуем v[j] с тем же ключом (i,j)\n",
    "    В итоге и A, и v попадают в my_map с одинаковыми coords.\n",
    "    \"\"\"\n",
    "    for i in range(A.shape[0]):\n",
    "        for j in range(A.shape[1]):\n",
    "            yield (i, j), A[i, j]\n",
    "            yield (i, j), v[j]\n",
    "\n",
    "\n",
    "mv_res = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "print(\"MAT×VEC:\", mv_res)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAT×VEC: [(0, 3.0142366538715084), (1, 7.645696316137098), (2, 5.932406207646883), (3, 5.626846825981297), (4, 4.492509837857999)]\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GIo2t7nNxvA9"
   },
   "source": [
    "## Matrix multiplication (Перемножение матриц)\n",
    "\n",
    "Если у нас есть матрица $M$ с элементами $m_{ij}$ в строке $i$ и столбце $j$, и матрица $N$ с элементами $n_{jk}$ в строке $j$ и столбце $k$, тогда их произведение $P = MN$ есть матрица $P$ с элементами $p_{ik}$ в строке $i$ и столбце $k$, где\n",
    "\n",
    "$$p_{ik} =\\sum_{j} m_{ij}n_{jk}$$\n",
    "\n",
    "Необходимым требованием является одинаковое количество столбцов в $M$ и строк в $N$, чтобы операция суммирования по  $j$ была осмысленной. Мы можем размышлять о матрице, как об отношении с тремя атрибутами: номер строки, номер столбца, само значение. Таким образом матрица $M$ предстваляется как отношение $ M(I, J, V )$, с кортежами $(i, j, m_{ij})$, и, аналогично, матрица $N$ представляется как отношение $N(J, K, W)$, с кортежами $(j, k, n_{jk})$. Так как большие матрицы как правило разреженные (большинство значений равно 0), и так как мы можем нулевыми значениями пренебречь (не хранить), такое реляционное представление достаточно эффективно для больших матриц. Однако, возможно, что координаты $i$, $j$, и $k$ неявно закодированы в смещение позиции элемента относительно начала файла, вместо явного хранения. Тогда, функция Map (или Reader) должна быть разработана таким образом, чтобы реконструировать компоненты $I$, $J$, и $K$ кортежей из смещения.\n",
    "\n",
    "Произведение $MN$ это фактически join, за которым следуют группировка по ключу и аггрегация. Таким образом join отношений $M(I, J, V )$ и $N(J, K, W)$, имеющих общим только атрибут $J$, создаст кортежи $(i, j, k, v, w)$ из каждого кортежа $(i, j, v) \\in M$ и кортежа $(j, k, w) \\in N$. Такой 5 компонентный кортеж представляет пару элементов матрицы $(m_{ij} , n_{jk})$. Что нам хотелось бы получить на самом деле, это произведение этих элементов, то есть, 4 компонентный кортеж$(i, j, k, v \\times w)$, так как он представляет произведение $m_{ij}n_{jk}$. Мы представляем отношение как результат одной my_map_reduce операции, в которой мы можем произвести группировку и аггрегацию, с $I$ и $K$  атрибутами, по которым идёт группировка, и суммой  $V \\times W$.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1MBkGaLAYVCt",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.263640Z",
     "start_time": "2025-05-13T13:42:05.258807Z"
    }
   },
   "source": [
    "# my_map_reduce model\n",
    "def flatten(nested_iterable):\n",
    "    for iterable in nested_iterable:\n",
    "        for element in iterable:\n",
    "            yield element\n",
    "\n",
    "\n",
    "def group_by_key(iterable):\n",
    "    t = {}\n",
    "    for (k2, v2) in iterable:\n",
    "        t[k2] = t.get(k2, []) + [v2]\n",
    "    return t.items()\n",
    "\n",
    "\n",
    "def my_map_reduce(record_reader, my_map, my_reduce):\n",
    "    return flatten(map(lambda x: my_reduce(*x), group_by_key(flatten(map(lambda x: my_map(*x), record_reader())))))"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMspsOT0ZB35"
   },
   "source": "Реализуйте перемножение матриц с использованием модельного кода my_map_reduce для одной машины в случае, когда одна матрица хранится в памяти, а другая генерируется record_reader-ом."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "psP1XekbsEjS",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.326945Z",
     "start_time": "2025-05-13T13:42:05.321696Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "I = 2\n",
    "J = 3\n",
    "K = 4 * 10\n",
    "small_mat = np.random.rand(I, J)  # it is legal to access this from record_reader, my_map, my_reduce\n",
    "big_mat = np.random.rand(J, K)\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for j in range(big_mat.shape[0]):\n",
    "        for k in range(big_mat.shape[1]):\n",
    "            yield (j, k), big_mat[j, k]\n",
    "\n",
    "\n",
    "def my_map(k1, v1):\n",
    "    (j, k) = k1\n",
    "    w = v1\n",
    "    for i in range(I):\n",
    "        yield (i, k), (w * small_mat[i, j])\n",
    "\n",
    "\n",
    "def my_reduce(key, values):\n",
    "    yield key, sum(values)"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnt306LHhHrm"
   },
   "source": [
    "Проверьте своё решение"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Ewy_ZNYqW5a2",
    "outputId": "9ce264f2-9412-44e2-9b0a-cc780573ab3a",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.380645Z",
     "start_time": "2025-05-13T13:42:05.372640Z"
    }
   },
   "source": [
    "reference_solution = np.matmul(small_mat, big_mat)\n",
    "solution = my_map_reduce(record_reader, my_map, my_reduce)\n",
    "\n",
    "\n",
    "def asmatrix(reduce_output):\n",
    "    reduce_output = list(reduce_output)\n",
    "    a = max(i for ((i, k), vw) in reduce_output) + 1\n",
    "    b = max(k for ((i, k), vw) in reduce_output) + 1\n",
    "    mat = np.empty(shape=(a, b))\n",
    "    for ((i, k), vw) in reduce_output:\n",
    "        mat[i, k] = vw\n",
    "    return mat\n",
    "\n",
    "\n",
    "np.allclose(reference_solution, asmatrix(solution))  # should return true"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "TK7v4CEcfxqf",
    "outputId": "2c865d0a-4065-4e6b-c83f-5508ed5eb4fa",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.452140Z",
     "start_time": "2025-05-13T13:42:05.446764Z"
    }
   },
   "source": [
    "reduce_output = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "max(i for ((i, k), vw) in reduce_output)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4yyg3kOZqJJ"
   },
   "source": "Реализуйте перемножение матриц  с использованием модельного кода my_map_reduce для одной машины в случае, когда обе матрицы генерируются в record_reader. Например, сначала одна, а потом другая."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3B7rIAJCaHZq",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.506596Z",
     "start_time": "2025-05-13T13:42:05.495044Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# вспомогательные утилиты форматирования\n",
    "# -----------------------------------------------------------\n",
    "def tolist2d(reduce_out):\n",
    "    \"\"\"[( (i,k), value ), … ]  →  2-D list  [[...], [...], ...]\"\"\"\n",
    "    if isinstance(reduce_out[0][0], tuple):  # обычный вариант\n",
    "        a = max(i for (i, _), _v in reduce_out) + 1\n",
    "        b = max(k for (_, k), _v in reduce_out) + 1\n",
    "        mat = [[0.0] * b for _ in range(a)]\n",
    "        for (i, k), v in reduce_out:\n",
    "            mat[i][k] = v\n",
    "        return mat\n",
    "    else:  # distributed (partition, list)\n",
    "        flat = []\n",
    "        for _pid, data in reduce_out:\n",
    "            flat.extend(data)\n",
    "        return tolist2d(flat)\n",
    "\n",
    "\n",
    "def print_matrix(mat, name):\n",
    "    print(f\"{name} ({len(mat)}×{len(mat[0])}):\")\n",
    "    for row in mat:\n",
    "        print(\"  \", \" \".join(f\"{x:8.4f}\" for x in row))\n",
    "    print()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Полное умножение M × N (одна машина)\n",
    "# ============================================================\n",
    "I, J, K = 2, 3, 12\n",
    "M = np.random.rand(I, J)\n",
    "N = np.random.rand(J, K)\n",
    "\n",
    "\n",
    "def record_reader():\n",
    "    for j in range(J):\n",
    "        for k in range(K):\n",
    "            yield (j, k), N[j, k], 'N'\n",
    "\n",
    "        for i in range(I):\n",
    "            yield (i, j), M[i, j], 'M'\n",
    "\n",
    "\n",
    "def my_map(coord, val, tag):\n",
    "    if tag == 'N':\n",
    "        j, k = coord\n",
    "        for i in range(I):\n",
    "            yield (i, k), (j, val)\n",
    "\n",
    "    else:  # tag == 'M'\n",
    "        i, j = coord\n",
    "        for k in range(K):\n",
    "            yield (i, k), (j, val)\n",
    "\n",
    "\n",
    "def my_reduce(idx, pairs):\n",
    "    bucket = {}\n",
    "\n",
    "    for j, x in pairs:\n",
    "        bucket.setdefault(j, []).append(x)\n",
    "    s = 0.0\n",
    "\n",
    "    for j, lst in bucket.items():\n",
    "        if len(lst) == 2:\n",
    "            s += lst[0] * lst[1]\n",
    "    yield idx, float(s)\n",
    "\n",
    "\n",
    "matmul_pairs = list(my_map_reduce(record_reader, my_map, my_reduce))\n",
    "matmul_matrix = np.array(tolist2d(matmul_pairs))\n",
    "print_matrix(matmul_matrix, \"MAT×MAT result\")\n",
    "\n",
    "# быстрая проверка\n",
    "print(\"check :\", np.allclose(matmul_matrix, M @ N), \"\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAT×MAT result (2×12):\n",
      "     0.5919   1.0228   0.9136   0.7980   0.5115   1.0181   0.5508   0.8271   0.7304   0.6284   0.4280   0.6614\n",
      "     0.5685   0.9828   0.8950   0.8435   0.4969   1.0520   0.5382   0.8056   0.6416   0.6949   0.3754   0.6281\n",
      "\n",
      "check : True \n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXyzQi1DaIwo"
   },
   "source": "Реализуйте перемножение матриц с использованием модельного кода my_map_reduce Distributed, когда каждая матрица генерируется в своём record_reader."
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TDM_s78Rb5eR",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.578545Z",
     "start_time": "2025-05-13T13:42:05.571449Z"
    }
   },
   "source": [
    "maps, reducers = 2, 2\n",
    "\n",
    "\n",
    "def record_reader(i_max, j_max, tag):\n",
    "    if tag == 'M':\n",
    "        for i in range(I):\n",
    "            for j in range(J):\n",
    "                yield (i, j), M[i, j], 'M'\n",
    "    else:\n",
    "        for j in range(J):\n",
    "            for k in range(K):\n",
    "                yield (j, k), N[j, k], 'N'\n",
    "\n",
    "\n",
    "def input_format():\n",
    "    yield record_reader(I, J, 'M')\n",
    "    yield record_reader(J, K, 'N')\n",
    "\n",
    "\n",
    "dist1 = [(pid, list(part))  # материализуем генератор\n",
    "         for pid, part in map_reduce_distributed(\n",
    "        input_format, my_map, my_reduce,\n",
    "        combiner=None, partitioner=partitioner)]\n",
    "\n",
    "matmul_matrix_d1 = np.array(tolist2d(dist1))\n",
    "print_matrix(matmul_matrix_d1, \"distributed #1\")\n",
    "\n",
    "print(\"check :\", np.allclose(matmul_matrix_d1, M @ N), \"\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 key-value pairs were sent over a network.\n",
      "distributed #1 (2×12):\n",
      "     0.5919   1.0228   0.9136   0.7980   0.5115   1.0181   0.5508   0.8271   0.7304   0.6284   0.4280   0.6614\n",
      "     0.5685   0.9828   0.8950   0.8435   0.4969   1.0520   0.5382   0.8056   0.6416   0.6949   0.3754   0.6281\n",
      "\n",
      "check : True \n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuSA2P9Db6UM"
   },
   "source": "Обобщите предыдущее решение на случай, когда каждая матрица генерируется несколькими record_reader-ами, и проверьте его работоспособность. Будет ли работать решение, если record_reader-ы будут генерировать случайное подмножество элементов матрицы?"
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ehN0FqRDcwU5",
    "ExecuteTime": {
     "end_time": "2025-05-13T13:42:05.631449Z",
     "start_time": "2025-05-13T13:42:05.623004Z"
    }
   },
   "source": [
    "maps, reducers = 5, 3\n",
    "I, J, K = 2, 3, 12\n",
    "M = np.random.rand(I, J)\n",
    "N = np.random.rand(J, K)\n",
    "\n",
    "\n",
    "def record_reader(idx_subset, tag):\n",
    "    for (i, j) in idx_subset:\n",
    "        if tag == 'M':\n",
    "            yield (i, j), M[i, j], 'M'\n",
    "        else:\n",
    "            yield (i, j), N[i, j], 'N'\n",
    "\n",
    "\n",
    "def input_format():\n",
    "    M_idx = [(i, j) for i in range(I) for j in range(J)]\n",
    "    N_idx = [(j, k) for j in range(J) for k in range(K)]\n",
    "    np.random.shuffle(M_idx)\n",
    "    np.random.shuffle(N_idx)\n",
    "\n",
    "    M_chunk = len(M_idx) // (maps // 2)\n",
    "    N_chunk = len(N_idx) // (maps - maps // 2)\n",
    "\n",
    "    for pos in range(0, len(M_idx), M_chunk):\n",
    "        yield record_reader(M_idx[pos:pos + M_chunk], 'M')\n",
    "    for pos in range(0, len(N_idx), N_chunk):\n",
    "        yield record_reader(N_idx[pos:pos + N_chunk], 'N')\n",
    "\n",
    "\n",
    "dist2 = [(pid, list(part))\n",
    "         for pid, part in map_reduce_distributed(\n",
    "        input_format, my_map, my_reduce,\n",
    "        combiner=None, partitioner=partitioner)]\n",
    "\n",
    "matmul_matrix_d2 = np.array(tolist2d(dist2))\n",
    "print_matrix(matmul_matrix_d2, \"distributed #2\")\n",
    "\n",
    "print(\"check :\", np.allclose(matmul_matrix_d2, M @ N))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 key-value pairs were sent over a network.\n",
      "distributed #2 (2×12):\n",
      "     0.6915   0.5360   1.5806   0.9690   0.8718   0.8431   1.4671   1.7091   0.7124   0.7674   0.8498   0.6003\n",
      "     0.5445   0.5935   1.1766   0.9324   0.8159   0.8013   1.1598   1.3969   0.9126   0.4123   0.5338   0.5215\n",
      "\n",
      "check : True\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
